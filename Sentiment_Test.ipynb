{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import re\n",
    "from langdetect import detect\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.tokenize import WordPunctTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok = WordPunctTokenizer()\n",
    "\n",
    "pat1 = r'@[A-Za-z0-9_]+' # For removing mentions.\n",
    "pat2 = r'https?://[^ ]+' # For removing links.\n",
    "combined_pat = r'|'.join((pat1, pat2)) # For removing links.\n",
    "www_pat = r'www.[^ ]+' # For removing links.\n",
    "negations_dic = {\"isn't\":\"is not\", \"aren't\":\"are not\", \"wasn't\":\"was not\", \"weren't\":\"were not\",\n",
    "                \"haven't\":\"have not\",\"hasn't\":\"has not\",\"hadn't\":\"had not\",\"won't\":\"will not\",\n",
    "                \"wouldn't\":\"would not\", \"don't\":\"do not\", \"doesn't\":\"does not\",\"didn't\":\"did not\",\n",
    "                \"can't\":\"can not\",\"couldn't\":\"could not\",\"shouldn't\":\"should not\",\"mightn't\":\"might not\",\n",
    "                \"mustn't\":\"must not\"} # For removing negations.\n",
    "neg_pattern = re.compile(r'\\b(' + '|'.join(negations_dic.keys()) + r')\\b') # For removing negations.\n",
    "\n",
    "def tweet_cleaner(text):\n",
    "      \"\"\" This cleans the tweets text content\n",
    "          so it can be machine readable.\n",
    "      \"\"\"\n",
    "      soup = BeautifulSoup(text, 'lxml') # Decodes HTML.\n",
    "      souped = soup.get_text()\n",
    "      try: # UTF decoding.\n",
    "          bom_removed = souped.decode(\"utf-8-sig\").replace(u\"\\ufffd\", \"?\")\n",
    "      except:\n",
    "          bom_removed = souped\n",
    "      stripped = re.sub(combined_pat, '', bom_removed) # Gets rid of links.\n",
    "      stripped = re.sub(www_pat, '', stripped) # Gets rid of links.\n",
    "      lower_case = stripped.lower()\n",
    "      neg_handled = neg_pattern.sub(lambda x: negations_dic[x.group()], lower_case)\n",
    "      letters_only = re.sub(\"[^a-zA-Z]\", \" \", neg_handled) # Only lets letters in.\n",
    "      words = [x for x  in tok.tokenize(letters_only) if len(x) > 1] # Below removes whitespace\n",
    "      return (\" \".join(words)).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('teslaFullDataset.csv', engine='python') #read in csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "767393\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Like count</th>\n",
       "      <th>Retweet count</th>\n",
       "      <th>date</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2019-02-28 23:40:44</td>\n",
       "      <td>with many stores closing going to be harder to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2019-02-28 23:38:48</td>\n",
       "      <td>tesla drives down price for model to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2019-02-28 23:50:31</td>\n",
       "      <td>feel like everyone is talking about the car bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2019-02-28 23:54:06</td>\n",
       "      <td>pixie is taking liking to tesla dogslife trave...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2019-02-28 23:52:55</td>\n",
       "      <td>and tesla hardworking brilliant workers</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Like count Retweet count                 date  \\\n",
       "0        1.0           0.0  2019-02-28 23:40:44   \n",
       "1        0.0           0.0  2019-02-28 23:38:48   \n",
       "2        0.0           0.0  2019-02-28 23:50:31   \n",
       "3        0.0           0.0  2019-02-28 23:54:06   \n",
       "4        0.0           0.0  2019-02-28 23:52:55   \n",
       "\n",
       "                                               tweet  \n",
       "0  with many stores closing going to be harder to...  \n",
       "1               tesla drives down price for model to  \n",
       "2  feel like everyone is talking about the car bu...  \n",
       "3  pixie is taking liking to tesla dogslife trave...  \n",
       "4            and tesla hardworking brilliant workers  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length_of_df = len(df)\n",
    "print(length_of_df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-236727c5aac9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tweet'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtweet_cleaner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tweet\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-a070791e9527>\u001b[0m in \u001b[0;36mtweet_cleaner\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     16\u001b[0m           \u001b[0mso\u001b[0m \u001b[0mit\u001b[0m \u001b[0mcan\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mmachine\u001b[0m \u001b[0mreadable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m       \"\"\"\n\u001b[0;32m---> 18\u001b[0;31m       \u001b[0msoup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'lxml'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Decodes HTML.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m       \u001b[0msouped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# UTF decoding.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/bs4/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, markup, features, builder, parse_only, from_encoding, exclude_encodings, element_classes, **kwargs)\u001b[0m\n\u001b[1;32m    337\u001b[0m         \u001b[0mrejections\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m         \u001b[0msuccess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m         for (self.markup, self.original_encoding, self.declared_html_encoding,\n\u001b[0m\u001b[1;32m    340\u001b[0m          \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontains_replacement_characters\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m              self.builder.prepare_markup(\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/bs4/builder/_lxml.py\u001b[0m in \u001b[0;36mprepare_markup\u001b[0;34m(self, markup, user_specified_encoding, exclude_encodings, document_declared_encoding)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0mtry_encodings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0muser_specified_encoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdocument_declared_encoding\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m         detector = EncodingDetector(\n\u001b[0m\u001b[1;32m    185\u001b[0m             markup, try_encodings, is_html, exclude_encodings)\n\u001b[1;32m    186\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mencoding\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdetector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencodings\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/bs4/dammit.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, markup, override_encodings, is_html, exclude_encodings)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m         \u001b[0;31m# First order of business: strip a byte-order mark.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmarkup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msniffed_encoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip_byte_order_mark\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmarkup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_usable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtried\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/bs4/dammit.py\u001b[0m in \u001b[0;36mstrip_byte_order_mark\u001b[0;34m(cls, data)\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0;31m# Unicode data cannot have a byte-order mark.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34mb'\\xfe\\xff'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    330\u001b[0m                \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'\\x00\\x00'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m             \u001b[0mencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-16be'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__nonzero__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1476\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1477\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__nonzero__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1478\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m   1479\u001b[0m             \u001b[0;34mf\"The truth value of a {type(self).__name__} is ambiguous. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1480\u001b[0m             \u001b[0;34m\"Use a.empty, a.bool(), a.item(), a.any() or a.all().\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all()."
     ]
    }
   ],
   "source": [
    "tic = time.perf_counter()\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    df['tweet'][row] = tweet_cleaner(df[\"tweet\"][row]) #why tf doesn't this work \n",
    "    \n",
    "toc = time.perf_counter()\n",
    "print(f\"Cleaned {len(df)} in {toc - tic:0.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Like count</th>\n",
       "      <th>Retweet count</th>\n",
       "      <th>date</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4000</th>\n",
       "      <td>23.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2019-02-25 11:05:09</td>\n",
       "      <td>#Tesla Model S and X will now come standard wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4001</th>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2019-02-25 10:30:07</td>\n",
       "      <td>Tesla aumenta las entregas del Model 3 en Chin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4002</th>\n",
       "      <td>12.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2019-02-25 10:53:43</td>\n",
       "      <td>Titulares de Lunes 25 de Febrero de 2019 en No...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4003</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2019-02-25 11:53:49</td>\n",
       "      <td>#TESLA, un actor claro en el #MWC19 https://t....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4004</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2019-02-25 11:41:10</td>\n",
       "      <td>Alexandre Brasseur (Vintage Mecanic): «On a fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4005</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2019-02-25 10:42:47</td>\n",
       "      <td>Alexandre Brasseur (Vintage Mecanic): «On a fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4006</th>\n",
       "      <td>26.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2019-02-25 12:09:09</td>\n",
       "      <td>Looks like this Model 3 is getting checked out...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4007</th>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2019-02-25 11:24:59</td>\n",
       "      <td>The #Tesla #Model3 is the number 🥇selling EV ⚡...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4008</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2019-02-25 10:41:20</td>\n",
       "      <td>Alexandre Brasseur (Vintage Mecanic): «On a fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4009</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2019-02-25 11:15:10</td>\n",
       "      <td>Los vehículos 🚗 más deseados en el mundo 🌎 bas...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Like count Retweet count                 date  \\\n",
       "4000       23.0           1.0  2019-02-25 11:05:09   \n",
       "4001       11.0           2.0  2019-02-25 10:30:07   \n",
       "4002       12.0           6.0  2019-02-25 10:53:43   \n",
       "4003        0.0           0.0  2019-02-25 11:53:49   \n",
       "4004        0.0           0.0  2019-02-25 11:41:10   \n",
       "4005        0.0           1.0  2019-02-25 10:42:47   \n",
       "4006       26.0           1.0  2019-02-25 12:09:09   \n",
       "4007        7.0           3.0  2019-02-25 11:24:59   \n",
       "4008        0.0           0.0  2019-02-25 10:41:20   \n",
       "4009        0.0           0.0  2019-02-25 11:15:10   \n",
       "\n",
       "                                                  tweet  \n",
       "4000  #Tesla Model S and X will now come standard wi...  \n",
       "4001  Tesla aumenta las entregas del Model 3 en Chin...  \n",
       "4002  Titulares de Lunes 25 de Febrero de 2019 en No...  \n",
       "4003  #TESLA, un actor claro en el #MWC19 https://t....  \n",
       "4004  Alexandre Brasseur (Vintage Mecanic): «On a fa...  \n",
       "4005  Alexandre Brasseur (Vintage Mecanic): «On a fa...  \n",
       "4006  Looks like this Model 3 is getting checked out...  \n",
       "4007  The #Tesla #Model3 is the number 🥇selling EV ⚡...  \n",
       "4008  Alexandre Brasseur (Vintage Mecanic): «On a fa...  \n",
       "4009  Los vehículos 🚗 más deseados en el mundo 🌎 bas...  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[4000:4010] #ceck random range of dataset to ensure it was properly cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.drop('Source', inplace=True, axis=1)\n",
    "#df.drop('Unnamed: 0', inplace=True, axis=1)\n",
    "#df.drop('tweet_id', inplace=True, axis=1)\n",
    "#df.drop('User location', inplace = True, axis = 1) #delete columns we don't need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = len(df)\n",
    "i = 0 #remove \n",
    "for index, row in df.iterrows():\n",
    "    if detect(df[\"tweet\"][row])!= 'en': #this should work?\n",
    "        df.drop(index, inplace=True)\n",
    "print(j - len(df), \"rows removed\") #print tumber of rows that got removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "sid = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentimentScore(Tweet):\n",
    "    analyser = SentimentIntensityAnalyzer()\n",
    "    score_values = []\n",
    "    for tweet in df['tweet']:\n",
    "        vs1 = analyzer.polarity_scores(tweet)\n",
    "        score_values.append(vs1)\n",
    "    return score_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_scores = pd.DataFrame(sentimentScore(df['tweet']))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
